{
  "paragraphs": [
    {
      "text": "import org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.udf",
      "user": "anonymous",
      "dateUpdated": "Apr 22, 2017 1:58:22 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nimport org.apache.spark.sql.SparkSession\n\nimport org.apache.spark.sql.Row\n\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.sql.functions.udf\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1492801965154_-933441345",
      "id": "20170421-151245_533549501",
      "dateCreated": "Apr 21, 2017 3:12:45 PM",
      "dateStarted": "Apr 22, 2017 1:58:22 PM",
      "dateFinished": "Apr 22, 2017 1:58:23 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val spark \u003d SparkSession.builder().appName(\"pCTR\").getOrCreate() // start the spark session\nvar train_data \u003d sqlContext.read.format(\"com.databricks.spark.csv\") // read in main training file\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/Users/JCFL/Code/CT/Data Science/Assignment2+3/data/track2/training.txt\")",
      "user": "anonymous",
      "dateUpdated": "Apr 22, 2017 1:58:24 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nspark: org.apache.spark.sql.SparkSession \u003d org.apache.spark.sql.SparkSession@7600e9d1\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [_c0: string, _c1: string ... 10 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1492803032155_1867275071",
      "id": "20170421-153032_743090305",
      "dateCreated": "Apr 21, 2017 3:30:32 PM",
      "dateStarted": "Apr 22, 2017 1:58:24 PM",
      "dateFinished": "Apr 22, 2017 1:58:24 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// import additional data files\n\nvar descriptions_df \u003d sqlContext.read.format(\"com.databricks.spark.csv\") // read in descriptions file\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/Users/JCFL/Code/CT/Data Science/Assignment2+3/data/track2/descriptionid_tokensid.txt\")\n    \ndescriptions_df.printSchema()\n\nvar keywords_df \u003d sqlContext.read.format(\"com.databricks.spark.csv\") // read in keywords file\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/Users/JCFL/Code/CT/Data Science/Assignment2+3/data/track2/purchasedkeywordid_tokensid.txt\")\n    \nkeywords_df.printSchema()\n\nvar query_df \u003d sqlContext.read.format(\"com.databricks.spark.csv\") // read in query file\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/Users/JCFL/Code/CT/Data Science/Assignment2+3/data/track2/queryid_tokensid.txt\")\n    \nquery_df.printSchema()\n\nvar title_df \u003d sqlContext.read.format(\"com.databricks.spark.csv\") // read in title id\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/Users/JCFL/Code/CT/Data Science/Assignment2+3/data/track2/titleid_tokensid.txt\")\n\ntitle_df.printSchema()\n\nvar userprofile_df \u003d  sqlContext.read.format(\"com.databricks.spark.csv\") // read in userprofile file\n    .option(\"delimiter\", \"\\t\")\n    .load(\"/Users/JCFL/Code/CT/Data Science/Assignment2+3/data/track2/userid_profile.txt\")\n    \nuserprofile_df.printSchema()",
      "user": "anonymous",
      "dateUpdated": "Apr 22, 2017 1:58:25 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ndescriptions_df: org.apache.spark.sql.DataFrame \u003d [_c0: string, _c1: string]\nroot\n |-- _c0: string (nullable \u003d true)\n |-- _c1: string (nullable \u003d true)\n\n\nkeywords_df: org.apache.spark.sql.DataFrame \u003d [_c0: string, _c1: string]\nroot\n |-- _c0: string (nullable \u003d true)\n |-- _c1: string (nullable \u003d true)\n\n\nquery_df: org.apache.spark.sql.DataFrame \u003d [_c0: string, _c1: string]\nroot\n |-- _c0: string (nullable \u003d true)\n |-- _c1: string (nullable \u003d true)\n\n\ntitle_df: org.apache.spark.sql.DataFrame \u003d [_c0: string, _c1: string]\nroot\n |-- _c0: string (nullable \u003d true)\n |-- _c1: string (nullable \u003d true)\n\n\nuserprofile_df: org.apache.spark.sql.DataFrame \u003d [_c0: string, _c1: string ... 1 more field]\nroot\n |-- _c0: string (nullable \u003d true)\n |-- _c1: string (nullable \u003d true)\n |-- _c2: string (nullable \u003d true)\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1492808977858_-354883347",
      "id": "20170421-170937_556376046",
      "dateCreated": "Apr 21, 2017 5:09:37 PM",
      "dateStarted": "Apr 22, 2017 1:58:25 PM",
      "dateFinished": "Apr 22, 2017 1:58:27 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "train_data \u003d train_data.withColumn(\"Click\", train_data(\"_c0\").cast(\"Int\")).drop(\"_c0\")\n                            .withColumn(\"Impression\", train_data(\"_c1\").cast(\"Int\")).drop(\"_c1\")\n                            .withColumn(\"DisplayURL\", train_data(\"_c2\")).drop(\"_c2\")\n                            .withColumn(\"AdID\", train_data(\"_c3\")).drop(\"_c3\")\n                            .withColumn(\"AdvertiserID\", train_data(\"_c4\")).drop(\"_c4\")\n                            .withColumn(\"Depth\", train_data(\"_c5\").cast(\"Int\")).drop(\"_c5\")\n                            .withColumn(\"Position\", train_data(\"_c6\").cast(\"Int\")).drop(\"_c6\")\n                            .withColumn(\"QueryID\", train_data(\"_c7\")).drop(\"_c7\")\n                            .withColumn(\"KeywordID\", train_data(\"_c8\")).drop(\"_c8\")\n                            .withColumn(\"TitleID\", train_data(\"_c9\")).drop(\"_c9\")\n                            .withColumn(\"DescriptionID\", train_data(\"_c10\")).drop(\"_c10\")\n                            .withColumn(\"UserID\", train_data(\"_c11\")).drop(\"_c11\")",
      "user": "anonymous",
      "dateUpdated": "Apr 22, 2017 1:58:29 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 10 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1492802307154_1671042741",
      "id": "20170421-151827_1285571777",
      "dateCreated": "Apr 21, 2017 3:18:27 PM",
      "dateStarted": "Apr 22, 2017 1:58:29 PM",
      "dateFinished": "Apr 22, 2017 1:58:30 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "train_data \u003d train_data.join(query_df, train_data(\"QueryID\") \u003d\u003d\u003d query_df(\"_c0\"))\ntrain_data \u003d train_data.withColumn(\"QueryTokens\", train_data(\"_c1\")).drop(\"_c1\",\"_c0\")\n\ntrain_data \u003d train_data.join(keywords_df, train_data(\"KeywordID\") \u003d\u003d\u003d keywords_df(\"_c0\"))\ntrain_data \u003d train_data.withColumn(\"KeywordTokens\", train_data(\"_c1\")).drop(\"_c1\",\"_c0\")\n\ntrain_data \u003d train_data.join(title_df, train_data(\"TitleID\") \u003d\u003d\u003d title_df(\"_c0\"))\ntrain_data \u003d train_data.withColumn(\"TitleTokens\", train_data(\"_c1\")).drop(\"_c1\",\"_c0\")\n\ntrain_data \u003d train_data.join(descriptions_df, train_data(\"DescriptionID\") \u003d\u003d\u003d descriptions_df(\"_c0\"))\ntrain_data \u003d train_data.withColumn(\"DescriptionTokens\", train_data(\"_c1\")).drop(\"_c1\",\"_c0\")\n\ntrain_data \u003d train_data.join(userprofile_df, train_data(\"UserID\") \u003d\u003d\u003d userprofile_df(\"_c0\"))\ntrain_data \u003d train_data.withColumn(\"Gender\", train_data(\"_c1\")).drop(\"_c1\",\"_c0\")\ntrain_data \u003d train_data.withColumn(\"Age\", train_data(\"_c2\")).drop(\"_c2\")",
      "user": "anonymous",
      "dateUpdated": "Apr 22, 2017 1:58:37 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 12 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 11 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 13 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 12 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 14 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 13 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 15 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 14 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 17 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 16 more fields]\n\ntrain_data: org.apache.spark.sql.DataFrame \u003d [Click: int, Impression: int ... 16 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1492815970511_2087863799",
      "id": "20170421-190610_976225722",
      "dateCreated": "Apr 21, 2017 7:06:10 PM",
      "dateStarted": "Apr 22, 2017 1:58:33 PM",
      "dateFinished": "Apr 22, 2017 1:58:34 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// check for duplicate rows \nvar top25k \u003d train_data.groupBy(\"AdID\", \"QueryID\").count()",
      "user": "anonymous",
      "dateUpdated": "Apr 22, 2017 1:59:38 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ntop25k: org.apache.spark.sql.DataFrame \u003d [AdID: string, QueryID: string ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1492874335536_762320124",
      "id": "20170422-111855_1204545464",
      "dateCreated": "Apr 22, 2017 11:18:55 AM",
      "dateStarted": "Apr 22, 2017 1:59:38 PM",
      "dateFinished": "Apr 22, 2017 1:59:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\"hey\"",
      "user": "anonymous",
      "dateUpdated": "Apr 22, 2017 1:59:35 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nres19: String \u003d hey\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1492881678662_-994560564",
      "id": "20170422-132118_1104224237",
      "dateCreated": "Apr 22, 2017 1:21:18 PM",
      "dateStarted": "Apr 22, 2017 1:59:35 PM",
      "dateFinished": "Apr 22, 2017 1:59:35 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1492883951372_-1431606310",
      "id": "20170422-135911_843405127",
      "dateCreated": "Apr 22, 2017 1:59:11 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "DS_Assignment_2+3",
  "id": "2CEJQBAAM",
  "angularObjects": {
    "2C83U15KY:shared_process": [],
    "2CAWWSCV5:shared_process": [],
    "2C99ZZ81J:shared_process": [],
    "2C889Q97U:shared_process": [],
    "2CBG7NMAB:shared_process": [],
    "2C9EMJ73Q:shared_process": [],
    "2C8BJSWXS:shared_process": [],
    "2C9A1UZ9X:shared_process": [],
    "2C8GAKRNU:shared_process": [],
    "2C9QTNTQ1:shared_process": [],
    "2C9QNUN1V:shared_process": [],
    "2C9HCN6K2:shared_process": [],
    "2CA3DHNW9:shared_process": [],
    "2C9TDQ4J3:shared_process": [],
    "2C9MBBC1P:shared_process": [],
    "2C9NQEYWK:shared_process": [],
    "2C8SUY428:shared_process": [],
    "2CBCYSCVS:shared_process": [],
    "2CBBWR6KB:shared_process": []
  },
  "config": {
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}